{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import math\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian_filter_1d(center, var=1, filter_size=5, filter_range=None):\n",
    "    if filter_range is None:\n",
    "        x = torch.linspace(center - var * 2, center + var * 2, filter_size)\n",
    "    else:\n",
    "        x = torch.linspace(filter_range[0], filter_range[1], filter_size) - center\n",
    "    fx = (1 / (2 * math.pi * var) ** .5) * torch.exp(-(x ** 2 / (2 * var)))\n",
    "    return fx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GaussianRadialLayer(torch.nn.Module):\n",
    "    def __init__(self,input_channels=1,output_channels=8,radius=1,filter_sz=9,variance=1):\n",
    "        super(GaussianRadialLayer,self).__init__()\n",
    "        assert filter_sz % 2 ==1\n",
    "        \n",
    "        self.filter_sz=filter_sz\n",
    "        self.filter_from=-(filter_sz/2)\n",
    "        self.filter_to=(filter_sz/2)\n",
    "        self.output_channels=output_channels\n",
    "        \n",
    "        self.radius=torch.nn.Parameter(torch.tensor(float(radius)))\n",
    "        self.channel_weights=torch.nn.Parameter(torch.ones(input_channels).view([1,-1,1,1]))\n",
    "        \n",
    "        self.register_buffer(\"pi\",torch.tensor(float(math.pi)))\n",
    "        self.register_buffer(\"variance\",torch.tensor(float(variance)))\n",
    "        #precomputing tensors\n",
    "        self.register_buffer(\"filter_x\",torch.linspace(self.filter_from, self.filter_to,self.filter_sz).view([1,1,-1,1]).repeat(output_channels,1,1,1))\n",
    "        self.register_buffer(\"filter_y\",torch.linspace(self.filter_from, self.filter_to,self.filter_sz).view([1,1,1,-1]).repeat(output_channels,1,1,1))\n",
    "        self.register_buffer(\"x_angles\",torch.cos(torch.linspace(0,math.pi*2,output_channels+1)[:-1].view(-1,1,1,1)))\n",
    "        self.register_buffer(\"y_angles\",torch.sin(torch.linspace(0,math.pi*2,output_channels+1)[:-1].view(-1,1,1,1)))\n",
    "\n",
    "    def forward(self,input_tensors):\n",
    "        batch_sz,in_channels,x,y=input_tensors.size()\n",
    "        x_field = self.filter_x-self.x_angles*self.radius\n",
    "        y_field = self.filter_y-self.y_angles*self.radius\n",
    "        filter_x=(1 / (2 * self.pi * self.variance) ** .5) * torch.exp(-(x_field ** 2 / (2 * self.variance)))\n",
    "        filter_y=(1 / (2 * self.pi * self.variance) ** .5) * torch.exp(-(y_field ** 2 / (2 * self.variance)))\n",
    "        filter_x=filter_x*self.channel_weights\n",
    "        x_applied=F.conv2d(input_tensors,filter_x,padding=[self.filter_sz/2,0])\n",
    "        y_applied=F.conv2d(x_applied,filter_y,padding=[0,self.filter_sz/2],groups=self.output_channels)\n",
    "        return y_applied\n",
    "\n",
    "class DeltaLayer(torch.nn.Module):\n",
    "    def __init__(self,input_channels=1,radius=1,output_channels=8,filter_sz=9,variance=1,single_input_reference=False):\n",
    "        super(DeltaLayer,self).__init__()\n",
    "        self.radial=GaussianRadialLayer(input_channels=input_channels,output_channels=output_channels,radius=radius,filter_sz=filter_sz,variance=variance)\n",
    "        self.radial_bias=torch.nn.Parameter(torch.zeros([1,output_channels,1,1]))\n",
    "        if single_input_reference:\n",
    "            self.input_reference=torch.nn.Conv2d(input_channels,1,1)\n",
    "            self.input_reference.weight.data[:]=1.0/input_channels\n",
    "            self.input_reference.bias.data[:]=0\n",
    "        else:\n",
    "            self.input_reference=torch.nn.Conv2d(input_channels,output_channels,1)\n",
    "    \n",
    "    def forward(self,input_tensors):\n",
    "        radial=self.radial(input_tensors)+self.radial_bias\n",
    "        return radial-self.input_reference(input_tensors)\n",
    "\n",
    "class BinaryAlphabet(torch.nn.Module):\n",
    "    def __init__(self,input_channels):\n",
    "        super(BinaryAlphabet,self).__init__()\n",
    "        weight ,bias = BinaryAlphabet.create_binary_alphabet_filter_bank(input_channels)\n",
    "        self.register_buffer(\"weight\",weight)\n",
    "        self.register_buffer(\"bias\",bias)\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = torch.nn.functional.conv2d(x, weight=self.weight, groups=1)+self.bias[None,:,None,None]\n",
    "        return torch.relu(x)\n",
    "\n",
    "    @staticmethod\n",
    "    def create_binary_alphabet_filter_bank(input_channels):\n",
    "        W = torch.zeros([input_channels,2**input_channels])\n",
    "        words = torch.arange(2**input_channels, dtype=torch.int32)\n",
    "        b=[]\n",
    "        W=[]\n",
    "        for word in words:\n",
    "            bit_string=[word%2]\n",
    "            for pow in range(1,8):\n",
    "                bit_string.append(((word/2**pow)%2))\n",
    "            W.append([1.0 if n > 0 else float(-input_channels) for n in bit_string])\n",
    "            b.append(1.0 - sum(bit_string))\n",
    "        W=torch.Tensor(W).view(2**input_channels, input_channels, 1, 1)\n",
    "        b=torch.Tensor(b)\n",
    "        #W = torch.Tensor(W).reshape(words, input_channels, 1, 1)\n",
    "        return W, b\n",
    "\n",
    "class LBP(torch.nn.Module):\n",
    "    def __init__(self,input_channels=1,radius=1,circle_points=8,filter_sz=9,variance=1.0,delta_scale=2.0):\n",
    "        super(LBP,self).__init__()\n",
    "        self.scale_delta=delta_scale\n",
    "        self.delta=DeltaLayer(input_channels=input_channels,output_channels=circle_points,radius=radius,filter_sz=filter_sz,variance=variance)\n",
    "        self.binary_alphabet=BinaryAlphabet(input_channels=circle_points)\n",
    "    def forward(self,x):\n",
    "        return self.binary_alphabet(torch.relu(self.delta(x))*self.scale_delta)\n",
    "    def get_radial_constraint(self):\n",
    "        return torch.relu(-self.delta.radial.radius)+torch.relu(-self.delta.radial.filter_sz/2+self.delta.radial.radius+2*self.delta.radial.radius)\n",
    "\n",
    "class LbpNet(torch.nn.Module):\n",
    "    def __init__(self,input_channels=1):\n",
    "        super(LbpNet,self).__init__()\n",
    "        self.lbp_layer1=LBP(input_channels=input_channels,circle_points=8,filter_sz=9,radius=2)\n",
    "        self.lbp_layer2=LBP(input_channels=256,circle_points=8,filter_sz=9,radius=2)\n",
    "        #self.lbp_layer2=LBP(input_channels=256,circle_points=8,filter_sz=9,radius=2)\n",
    "        self.mp2=torch.nn.MaxPool2d(2)\n",
    "        self.conv3=torch.nn.Conv2d(256,256,1)\n",
    "        self.sp7=torch.nn.AvgPool2d(7)\n",
    "        self.conv4=torch.nn.Conv2d(256,256,1)\n",
    "        self.global_pool=torch.nn.AdaptiveAvgPool2d((3,3))\n",
    "        self.fc1=torch.nn.Linear(256*3*3,128)\n",
    "        self.fc_class=torch.nn.Linear(128,10)\n",
    "\n",
    "    def forward(self,x):\n",
    "        x=self.lbp_layer1(x)\n",
    "        x=self.mp2(x)\n",
    "        x=torch.relu(x)\n",
    "\n",
    "        x=self.lbp_layer2(x)\n",
    "        x=self.mp2(x)\n",
    "        x=torch.relu(x)\n",
    "        \n",
    "        x=self.conv3(x)\n",
    "        x=self.mp2(x)\n",
    "        x=torch.relu(x)\n",
    "        \n",
    "        x=self.conv4(x)\n",
    "        x=torch.relu(x)\n",
    "        #x=self.sp7(x)\n",
    "        x=self.global_pool(x)\n",
    "        x=self.fc1(x.view(x.size(0),-1))\n",
    "        x=torch.relu(x)\n",
    "        \n",
    "        x=self.fc_class(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "    def __str__(self):\n",
    "        return \"LbpNet(radius={:.4f},radius={:.4f})\".format(float(self.lbp_layer1.delta.radial.radius.data),float(self.lbp_layer2.delta.radial.radius.data))\n",
    "\n",
    "    def get_radial_constraint(self):\n",
    "        return self.lbp_layer1.get_radial_constraint() + self.lbp_layer2.get_radial_constraint()\n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "class CnnNet(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CnnNet,self).__init__()\n",
    "        #self.lbp_layer1=LBP(input_channels=1,circle_points=8,filter_sz=9,radius=2)\n",
    "        self.conv1=torch.nn.Conv2d(1,256,3,padding=1)\n",
    "        #self.lbp_layer2=LBP(input_channels=256,circle_points=8,filter_sz=9,radius=2)\n",
    "        self.mp2=torch.nn.MaxPool2d(2)\n",
    "        self.conv3=torch.nn.Conv2d(256,256,1)\n",
    "        self.conv4=torch.nn.Conv2d(256,256,1)\n",
    "        self.fc1=torch.nn.Linear(256*14*14,128)\n",
    "        self.fc_class=torch.nn.Linear(128,10)\n",
    "\n",
    "    def forward(self,x):\n",
    "        x=self.conv1(x)\n",
    "        x=self.mp2(x)\n",
    "        x=torch.relu(x)\n",
    "        \n",
    "        x=self.conv3(x)\n",
    "        x=torch.relu(x)        \n",
    "        #x=self.sp7(x)\n",
    "        x=self.fc1(x.view(x.size(0),-1))\n",
    "        x=torch.relu(x)        \n",
    "        x=self.fc_class(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "    \n",
    "    def get_radial_constraint(self):\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, device, train_loader, optimizer, epoch,log_interval=100):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.nll_loss(output, target)+model.get_radial_constraint()**2\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % log_interval == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))\n",
    "\n",
    "\n",
    "def test(model, device, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\n",
    "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "\n",
    "    print('{}: Test loss: {:.4f}, Test Acc.: {}/{} ({:.0f}%)\\n'.format(str(model).split(\"\\n\")[0],\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lbp_layer1.delta.radial_bias -> torch.Size([1, 8, 1, 1])\n",
      "lbp_layer1.delta.radial.radius -> torch.Size([])\n",
      "lbp_layer1.delta.radial.channel_weights -> torch.Size([1, 1, 1, 1])\n",
      "lbp_layer1.delta.input_reference.weight -> torch.Size([8, 1, 1, 1])\n",
      "lbp_layer1.delta.input_reference.bias -> torch.Size([8])\n",
      "lbp_layer2.delta.radial_bias -> torch.Size([1, 8, 1, 1])\n",
      "lbp_layer2.delta.radial.radius -> torch.Size([])\n",
      "lbp_layer2.delta.radial.channel_weights -> torch.Size([1, 256, 1, 1])\n",
      "lbp_layer2.delta.input_reference.weight -> torch.Size([8, 256, 1, 1])\n",
      "lbp_layer2.delta.input_reference.bias -> torch.Size([8])\n",
      "conv3.weight -> torch.Size([256, 256, 1, 1])\n",
      "conv3.bias -> torch.Size([256])\n",
      "conv4.weight -> torch.Size([256, 256, 1, 1])\n",
      "conv4.bias -> torch.Size([256])\n",
      "fc1.weight -> torch.Size([128, 2304])\n",
      "fc1.bias -> torch.Size([128])\n",
      "fc_class.weight -> torch.Size([10, 128])\n",
      "fc_class.bias -> torch.Size([10])\n",
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 9.204246\n",
      "Train Epoch: 1 [20000/60000 (33%)]\tLoss: 0.920948\n",
      "Train Epoch: 1 [40000/60000 (67%)]\tLoss: 0.761670\n",
      "1 LbpNet(radius=1.2411,radius=1.3702): Test loss: 0.6268, Test Acc.: 7559/10000 (76%)\n",
      "\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.619724\n",
      "Train Epoch: 2 [20000/60000 (33%)]\tLoss: 0.478855\n",
      "Train Epoch: 2 [40000/60000 (67%)]\tLoss: 0.535583\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-fde6bae69130>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m150\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m     \u001b[0;32mprint\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-b18fe5d41858>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, device, train_loader, optimizer, epoch, log_interval)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m         \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\")\n",
    "batch_size=200\n",
    "test_batch_size=100\n",
    "train_ds=datasets.FashionMNIST('../data', train=True, download=True,\n",
    "                       transform=transforms.Compose([\n",
    "                           transforms.ToTensor(),\n",
    "                           transforms.Normalize((0.1307,), (0.3081,))\n",
    "                       ]))\n",
    "#train_ds=[train_ds[n] for n in range(0,len(train_ds),len(train_ds)/2000)]\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_ds,batch_size=batch_size, shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "        datasets.FashionMNIST('../data', train=False, transform=transforms.Compose([\n",
    "                           transforms.ToTensor(),\n",
    "                           transforms.Normalize((0.1307,), (0.3081,))\n",
    "                       ])),\n",
    "        batch_size=test_batch_size, shuffle=True)\n",
    "\n",
    "model = LbpNet().to(device)\n",
    "#model = CnnNet().to(device)\n",
    "\n",
    "for name,p in model.named_parameters():\n",
    "    print name,\"->\",p.data.size()\n",
    "    optimizer = torch.optim.SGD([p], lr=.001, momentum=.9)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=.001, momentum=.9)\n",
    "\n",
    "for epoch in range(1, 150):\n",
    "    train(model, device, train_loader, optimizer, epoch)\n",
    "    print epoch,\n",
    "    test(model, device, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "impulse=torch.zeros(1,1,19,19);impulse[:,:,9,9]=1\n",
    "img=torch.zeros(1,1,501,501);img[:,:,22:30,22:30]=1;img[:,:,8:13,8:13]=1\n",
    "img=img.cuda()\n",
    "impulse=impulse.cuda()\n",
    "#%timeit _,lbp_img=ba(delta(img))[0,:,:,:].max(dim=0)\n",
    "_,lbp_img=model(img)#[0,:,:,:].max(dim=0)\n",
    "\n",
    "#conv2=torch.nn.Conv2d(1,8,31)\n",
    "fig,[ax1,ax2,ax3]=plt.subplots(1,3)\n",
    "im1=ax1.imshow(model.lbp_layer1.delta.radial(impulse)[0,:,:,:].sum(dim=0).detach().cpu().numpy())\n",
    "im2=ax2.imshow(delta_img[0,0,:40,:40].detach().cpu().numpy(),cmap=\"gray\")\n",
    "im3=ax3.imshow(lbp_img[:40,:40].detach().cpu().numpy(),cmap=\"d256\")\n",
    "fig.colorbar(im1)#, cax=cax, orientation='horizontal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
