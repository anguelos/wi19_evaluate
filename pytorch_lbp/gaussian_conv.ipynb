{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import math\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian_filter_1d(center, var=1, filter_size=5, filter_range=None):\n",
    "    if filter_range is None:\n",
    "        x = torch.linspace(center - var * 2, center + var * 2, filter_size)\n",
    "    else:\n",
    "        x = torch.linspace(filter_range[0], filter_range[1], filter_size) - center\n",
    "    fx = (1 / (2 * math.pi * var) ** .5) * torch.exp(-(x ** 2 / (2 * var)))\n",
    "    return fx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GaussianRadialLayer(torch.nn.Module):\n",
    "    def __init__(self,input_channels=1,output_channels=8,radius=1,filter_sz=9,variance=1):\n",
    "        super(GaussianRadialLayer,self).__init__()\n",
    "        assert filter_sz % 2 ==1\n",
    "        \n",
    "        self.filter_sz=filter_sz\n",
    "        self.filter_from=-(filter_sz/2)\n",
    "        self.filter_to=(filter_sz/2)\n",
    "        self.output_channels=output_channels\n",
    "        \n",
    "        self.radius=torch.nn.Parameter(torch.tensor(float(radius)))\n",
    "        self.channel_weights=torch.nn.Parameter(torch.ones(input_channels).view([1,-1,1,1]))\n",
    "        \n",
    "        self.register_buffer(\"pi\",torch.tensor(float(math.pi)))\n",
    "        self.register_buffer(\"variance\",torch.tensor(float(variance)))\n",
    "        #precomputing tensors\n",
    "        self.register_buffer(\"filter_x\",torch.linspace(self.filter_from, self.filter_to,self.filter_sz).view([1,1,-1,1]).repeat(output_channels,1,1,1))\n",
    "        self.register_buffer(\"filter_y\",torch.linspace(self.filter_from, self.filter_to,self.filter_sz).view([1,1,1,-1]).repeat(output_channels,1,1,1))\n",
    "        self.register_buffer(\"x_angles\",torch.cos(torch.linspace(0,math.pi*2,output_channels+1)[:-1].view(-1,1,1,1)))\n",
    "        self.register_buffer(\"y_angles\",torch.sin(torch.linspace(0,math.pi*2,output_channels+1)[:-1].view(-1,1,1,1)))\n",
    "\n",
    "    def forward(self,input_tensors):\n",
    "        batch_sz,in_channels,x,y=input_tensors.size()\n",
    "        x_field = self.filter_x-self.x_angles*self.radius\n",
    "        y_field = self.filter_y-self.y_angles*self.radius\n",
    "        filter_x=(1 / (2 * self.pi * self.variance) ** .5) * torch.exp(-(x_field ** 2 / (2 * self.variance)))\n",
    "        filter_y=(1 / (2 * self.pi * self.variance) ** .5) * torch.exp(-(y_field ** 2 / (2 * self.variance)))\n",
    "        filter_x=filter_x*self.channel_weights\n",
    "        x_applied=F.conv2d(input_tensors,filter_x,padding=[self.filter_sz/2,0])\n",
    "        y_applied=F.conv2d(x_applied,filter_y,padding=[0,self.filter_sz/2],groups=self.output_channels)\n",
    "        return y_applied\n",
    "\n",
    "class DeltaLayer(torch.nn.Module):\n",
    "    def __init__(self,input_channels=1,radius=1,output_channels=8,filter_sz=9,variance=1,single_input_reference=False):\n",
    "        super(DeltaLayer,self).__init__()\n",
    "        self.radial=GaussianRadialLayer(input_channels=input_channels,output_channels=output_channels,radius=radius,filter_sz=filter_sz,variance=variance)\n",
    "        self.radial_bias=torch.nn.Parameter(torch.zeros([1,output_channels,1,1]))\n",
    "        if single_input_reference:\n",
    "            self.input_reference=torch.nn.Conv2d(input_channels,1,1)\n",
    "            self.input_reference.weight.data[:]=1.0/input_channels\n",
    "            self.input_reference.bias.data[:]=0\n",
    "        else:\n",
    "            self.input_reference=torch.nn.Conv2d(input_channels,output_channels,1)\n",
    "    \n",
    "    def forward(self,input_tensors):\n",
    "        radial=self.radial(input_tensors)+self.radial_bias\n",
    "        return radial-self.input_reference(input_tensors)\n",
    "\n",
    "class BinaryAlphabet(torch.nn.Module):\n",
    "    def __init__(self,input_channels):\n",
    "        super(BinaryAlphabet,self).__init__()\n",
    "        weight ,bias = BinaryAlphabet.create_binary_alphabet_filter_bank(input_channels)\n",
    "        self.register_buffer(\"weight\",weight)\n",
    "        self.register_buffer(\"bias\",bias)\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = torch.nn.functional.conv2d(x, weight=self.weight, groups=1)+self.bias[None,:,None,None]\n",
    "        return torch.relu(x)\n",
    "\n",
    "    @staticmethod\n",
    "    def create_binary_alphabet_filter_bank(input_channels):\n",
    "        W = torch.zeros([input_channels,2**input_channels])\n",
    "        words = torch.arange(2**input_channels, dtype=torch.int32)\n",
    "        b=[]\n",
    "        W=[]\n",
    "        for word in words:\n",
    "            bit_string=[word%2]\n",
    "            for pow in range(1,8):\n",
    "                bit_string.append(((word/2**pow)%2))\n",
    "            W.append([1.0 if n > 0 else float(-input_channels) for n in bit_string])\n",
    "            b.append(1.0 - sum(bit_string))\n",
    "        W=torch.Tensor(W).view(2**input_channels, input_channels, 1, 1)\n",
    "        b=torch.Tensor(b)\n",
    "        #W = torch.Tensor(W).reshape(words, input_channels, 1, 1)\n",
    "        return W, b\n",
    "\n",
    "class LBP(torch.nn.Module):\n",
    "    def __init__(self,input_channels=1,radius=1,circle_points=8,filter_sz=9,variance=1.0,delta_scale=2.0):\n",
    "        super(LBP,self).__init__()\n",
    "        self.scale_delta=delta_scale\n",
    "        self.delta=DeltaLayer(input_channels=input_channels,output_channels=circle_points,radius=radius,filter_sz=filter_sz,variance=variance)\n",
    "        self.binary_alphabet=BinaryAlphabet(input_channels=circle_points)\n",
    "    def forward(self,x):\n",
    "        return self.binary_alphabet(torch.relu(self.delta(x))*self.scale_delta)\n",
    "    def get_radial_constraint(self):\n",
    "        return torch.relu(-self.delta.radial.radius)+torch.relu(-self.delta.radial.filter_sz/2+self.delta.radial.radius+2*self.delta.radial.radius)\n",
    "\n",
    "class LbpNet(torch.nn.Module):\n",
    "    def __init__(self,input_channels=1):\n",
    "        super(LbpNet,self).__init__()\n",
    "        self.lbp_layer1=LBP(input_channels=input_channels,circle_points=8,filter_sz=9,radius=2)\n",
    "        self.lbp_layer2=LBP(input_channels=256,circle_points=8,filter_sz=9,radius=2)\n",
    "        #self.lbp_layer2=LBP(input_channels=256,circle_points=8,filter_sz=9,radius=2)\n",
    "        self.mp2=torch.nn.MaxPool2d(2)\n",
    "        self.conv3=torch.nn.Conv2d(256,256,1)\n",
    "        self.sp7=torch.nn.AvgPool2d(7)\n",
    "        self.conv4=torch.nn.Conv2d(256,256,1)\n",
    "        self.global_pool=torch.nn.AdaptiveAvgPool2d((3,3))\n",
    "        self.fc1=torch.nn.Linear(256*3*3,128)\n",
    "        self.fc_class=torch.nn.Linear(128,10)\n",
    "\n",
    "    def forward(self,x):\n",
    "        x=self.lbp_layer1(x)\n",
    "        x=self.mp2(x)\n",
    "        x=torch.relu(x)\n",
    "\n",
    "        x=self.lbp_layer2(x)\n",
    "        x=self.mp2(x)\n",
    "        x=torch.relu(x)\n",
    "        \n",
    "        x=self.conv3(x)\n",
    "        x=self.mp2(x)\n",
    "        x=torch.relu(x)\n",
    "        \n",
    "        x=self.conv4(x)\n",
    "        x=torch.relu(x)\n",
    "        #x=self.sp7(x)\n",
    "        x=self.global_pool(x)\n",
    "        x=self.fc1(x.view(x.size(0),-1))\n",
    "        x=torch.relu(x)\n",
    "        \n",
    "        x=self.fc_class(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "    def __str__(self):\n",
    "        return \"LbpNet(radius={:.4f},radius={:.4f})\".format(float(self.lbp_layer1.delta.radial.radius.data),float(self.lbp_layer2.delta.radial.radius.data))\n",
    "\n",
    "    def get_radial_constraint(self):\n",
    "        return self.lbp_layer1.get_radial_constraint() + self.lbp_layer2.get_radial_constraint()\n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "class CnnNet(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CnnNet,self).__init__()\n",
    "        #self.lbp_layer1=LBP(input_channels=1,circle_points=8,filter_sz=9,radius=2)\n",
    "        self.conv1=torch.nn.Conv2d(1,256,3,padding=1)\n",
    "        #self.lbp_layer2=LBP(input_channels=256,circle_points=8,filter_sz=9,radius=2)\n",
    "        self.mp2=torch.nn.MaxPool2d(2)\n",
    "        self.conv3=torch.nn.Conv2d(256,256,1)\n",
    "        self.conv4=torch.nn.Conv2d(256,256,1)\n",
    "        self.fc1=torch.nn.Linear(256*14*14,128)\n",
    "        self.fc_class=torch.nn.Linear(128,10)\n",
    "\n",
    "    def forward(self,x):\n",
    "        x=self.conv1(x)\n",
    "        x=self.mp2(x)\n",
    "        x=torch.relu(x)\n",
    "        \n",
    "        x=self.conv3(x)\n",
    "        x=torch.relu(x)        \n",
    "        #x=self.sp7(x)\n",
    "        x=self.fc1(x.view(x.size(0),-1))\n",
    "        x=torch.relu(x)        \n",
    "        x=self.fc_class(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "    \n",
    "    def get_radial_constraint(self):\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, device, train_loader, optimizer, epoch,log_interval=100):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.nll_loss(output, target)+model.get_radial_constraint()**2\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % log_interval == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))\n",
    "\n",
    "\n",
    "def test(model, device, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\n",
    "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "\n",
    "    print('{}: Test loss: {:.4f}, Test Acc.: {}/{} ({:.0f}%)\\n'.format(str(model).split(\"\\n\")[0],\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "Not a gzipped file (b'<!')",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-32a41b6384e3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m                        transform=transforms.Compose([\n\u001b[1;32m      6\u001b[0m                            \u001b[0mtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mToTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m                            \u001b[0mtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.1307\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m0.3081\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m                        ]))\n\u001b[1;32m      9\u001b[0m \u001b[0;31m#train_ds=[train_ds[n] for n in range(0,len(train_ds),len(train_ds)/2000)]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torchvision/datasets/mnist.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root, train, transform, target_transform, download)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdownload\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_exists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torchvision/datasets/mnist.py\u001b[0m in \u001b[0;36mdownload\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.gz'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mout_f\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m                     \u001b[0mgzip\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGzipFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mzip_f\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m                 \u001b[0mout_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m             \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munlink\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/gzip.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, size)\u001b[0m\n\u001b[1;32m    274\u001b[0m             \u001b[0;32mimport\u001b[0m \u001b[0merrno\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merrno\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEBADF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"read() on write-only GzipFile object\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 276\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_buffer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    277\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/gzip.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, size)\u001b[0m\n\u001b[1;32m    461\u001b[0m                 \u001b[0;31m# jump to the next member, if there is one.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    462\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 463\u001b[0;31m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_gzip_header\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    464\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    465\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0;34mb\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/gzip.py\u001b[0m in \u001b[0;36m_read_gzip_header\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    409\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    410\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmagic\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34mb'\\037\\213'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 411\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Not a gzipped file (%r)'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mmagic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    412\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m         (method, flag,\n",
      "\u001b[0;31mOSError\u001b[0m: Not a gzipped file (b'<!')"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\")\n",
    "batch_size=200\n",
    "test_batch_size=100\n",
    "train_ds=datasets.FashionMNIST('../data', train=True, download=True,\n",
    "                       transform=transforms.Compose([\n",
    "                           transforms.ToTensor(),\n",
    "                           transforms.Normalize((0.1307,), (0.3081,))\n",
    "                       ]))\n",
    "#train_ds=[train_ds[n] for n in range(0,len(train_ds),len(train_ds)/2000)]\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_ds,batch_size=batch_size, shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "        datasets.FashionMNIST('../data', train=False, transform=transforms.Compose([\n",
    "                           transforms.ToTensor(),\n",
    "                           transforms.Normalize((0.1307,), (0.3081,))\n",
    "                       ])),\n",
    "        batch_size=test_batch_size, shuffle=True)\n",
    "\n",
    "model = LbpNet().to(device)\n",
    "#model = CnnNet().to(device)\n",
    "\n",
    "for name,p in model.named_parameters():\n",
    "    print (name,\"->\",p.data.size())\n",
    "    optimizer = torch.optim.SGD([p], lr=.001, momentum=.9)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=.001, momentum=.9)\n",
    "\n",
    "for epoch in range(1, 150):\n",
    "    train(model, device, train_loader, optimizer, epoch)\n",
    "    print(epoch,end=\"\")\n",
    "    test(model, device, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "impulse=torch.zeros(1,1,19,19);impulse[:,:,9,9]=1\n",
    "img=torch.zeros(1,1,501,501);img[:,:,22:30,22:30]=1;img[:,:,8:13,8:13]=1\n",
    "img=img.cuda()\n",
    "impulse=impulse.cuda()\n",
    "#%timeit _,lbp_img=ba(delta(img))[0,:,:,:].max(dim=0)\n",
    "_,lbp_img=model(img)#[0,:,:,:].max(dim=0)\n",
    "\n",
    "#conv2=torch.nn.Conv2d(1,8,31)\n",
    "fig,[ax1,ax2,ax3]=plt.subplots(1,3)\n",
    "im1=ax1.imshow(model.lbp_layer1.delta.radial(impulse)[0,:,:,:].sum(dim=0).detach().cpu().numpy())\n",
    "im2=ax2.imshow(delta_img[0,0,:40,:40].detach().cpu().numpy(),cmap=\"gray\")\n",
    "im3=ax3.imshow(lbp_img[:40,:40].detach().cpu().numpy(),cmap=\"d256\")\n",
    "fig.colorbar(im1)#, cax=cax, orientation='horizontal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
